{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This projects is coming as a subproject for Kaggle's competetion: `Two Sigma: Using News to Predict Stock Movements`.\n",
    "Basically its task is to predict if a given information/news brings positive or negative connotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model may be/will be used for predicting how a given information coming from News data may affect a company's stock prices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 NLTK modules for language processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk.corpus import state_union, wordnet, stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer #Stemming words e.g Writing -> Write\n",
    "\"\"\"Models for training and testing the results\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Keras - Deep LEarning models\n",
    "from keras.layers.core import Dense,Flatten,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Downloading NLTK submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Łukasz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Łukasz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Łukasz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Deep text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Uploading dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Liked\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/data.tsv', delimiter = '\\t')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 SentimentAnalyst class doing preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyst:\n",
    "    def __init__(self, df, feature_col, label_col):\n",
    "        self.data = df\n",
    "        self.corpora = None\n",
    "        self.feature_col = feature_col\n",
    "        self.label_col = label_col\n",
    "    \"\"\"Remove unnecessary symbols & lemmatization, stemming\"\"\"\n",
    "    def preprocess_data(self):\n",
    "        n_sentences = len(self.data)\n",
    "        corpora = []\n",
    "        ps = PorterStemmer()\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        for review_it in range(0, n_sentences):\n",
    "            review = re.sub('[^a-zA-Z]', ' ', self.data[self.feature_col][review_it])\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "            stemmed = []\n",
    "            for word in review:\n",
    "                if not word in stopwords.words('english'):\n",
    "                    word = lemmatizer.lemmatize(word)\n",
    "                    stemmed.append(ps.stem(word))   \n",
    "            review = stemmed\n",
    "            review = ' '.join(review)\n",
    "            corpora.append(review)\n",
    "        self.corpora = corpora\n",
    "        return corpora\n",
    "    \"\"\"Build vectors from words Bag of Words\"\"\"\n",
    "    \n",
    "    def vectorize(self, max_features):\n",
    "        cv = CountVectorizer(max_features = max_features)\n",
    "        X = cv.fit_transform(self.corpora).toarray()\n",
    "        Y = df[self.label_col].values\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Analyst object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = SentimentAnalyst(df, 'Review', \"Liked\")\n",
    "analyst.preprocess_data()\n",
    "X, Y = analyst.vectorize(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y) # Convertion into dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test  = train_test_split(X, Y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Building Deep Learning model (Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 32)                19232     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 38,050\n",
      "Trainable params: 38,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(units = 32, activation = 'relu', input_dim = X_train.shape[1]),\n",
    "    Dense(units = 64, activation = 'relu'),\n",
    "    Dense(units = 128, activation = 'relu'),\n",
    "    Dense(units = 64, activation = 'relu'),\n",
    "    Dense(units = 2, activation = 'sigmoid'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/500\n",
      "850/850 [==============================] - 0s 523us/step - loss: 0.6933 - acc: 0.5012 - val_loss: 0.6928 - val_acc: 0.5133\n",
      "Epoch 2/500\n",
      "850/850 [==============================] - 0s 77us/step - loss: 0.6924 - acc: 0.5565 - val_loss: 0.6926 - val_acc: 0.4933\n",
      "Epoch 3/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.6915 - acc: 0.5988 - val_loss: 0.6924 - val_acc: 0.5067\n",
      "Epoch 4/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.6906 - acc: 0.6294 - val_loss: 0.6922 - val_acc: 0.5067\n",
      "Epoch 5/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.6895 - acc: 0.6000 - val_loss: 0.6918 - val_acc: 0.5000\n",
      "Epoch 6/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6881 - acc: 0.6000 - val_loss: 0.6913 - val_acc: 0.4933\n",
      "Epoch 7/500\n",
      "850/850 [==============================] - 0s 76us/step - loss: 0.6864 - acc: 0.6282 - val_loss: 0.6906 - val_acc: 0.4933\n",
      "Epoch 8/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.6842 - acc: 0.6353 - val_loss: 0.6897 - val_acc: 0.4867\n",
      "Epoch 9/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6815 - acc: 0.6518 - val_loss: 0.6885 - val_acc: 0.4933\n",
      "Epoch 10/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.6781 - acc: 0.6600 - val_loss: 0.6869 - val_acc: 0.5133\n",
      "Epoch 11/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6739 - acc: 0.6694 - val_loss: 0.6849 - val_acc: 0.5467\n",
      "Epoch 12/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6687 - acc: 0.6859 - val_loss: 0.6823 - val_acc: 0.5867\n",
      "Epoch 13/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6623 - acc: 0.7176 - val_loss: 0.6796 - val_acc: 0.5800\n",
      "Epoch 14/500\n",
      "850/850 [==============================] - 0s 99us/step - loss: 0.6546 - acc: 0.7094 - val_loss: 0.6758 - val_acc: 0.5933\n",
      "Epoch 15/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.6453 - acc: 0.7329 - val_loss: 0.6713 - val_acc: 0.5933\n",
      "Epoch 16/500\n",
      "850/850 [==============================] - 0s 77us/step - loss: 0.6340 - acc: 0.7600 - val_loss: 0.6669 - val_acc: 0.6133\n",
      "Epoch 17/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.6205 - acc: 0.7624 - val_loss: 0.6608 - val_acc: 0.6200\n",
      "Epoch 18/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.6050 - acc: 0.7765 - val_loss: 0.6540 - val_acc: 0.6200\n",
      "Epoch 19/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.5871 - acc: 0.7918 - val_loss: 0.6495 - val_acc: 0.6200\n",
      "Epoch 20/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.5677 - acc: 0.7953 - val_loss: 0.6404 - val_acc: 0.6200\n",
      "Epoch 21/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.5464 - acc: 0.8024 - val_loss: 0.6333 - val_acc: 0.6133\n",
      "Epoch 22/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.5238 - acc: 0.8165 - val_loss: 0.6261 - val_acc: 0.6333\n",
      "Epoch 23/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.4997 - acc: 0.8153 - val_loss: 0.6192 - val_acc: 0.6200\n",
      "Epoch 24/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.4745 - acc: 0.8247 - val_loss: 0.6183 - val_acc: 0.6133\n",
      "Epoch 25/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.4501 - acc: 0.8271 - val_loss: 0.6131 - val_acc: 0.6333\n",
      "Epoch 26/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.4267 - acc: 0.8353 - val_loss: 0.6114 - val_acc: 0.6467\n",
      "Epoch 27/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.4046 - acc: 0.8365 - val_loss: 0.6066 - val_acc: 0.6467\n",
      "Epoch 28/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.3843 - acc: 0.8506 - val_loss: 0.6086 - val_acc: 0.6467\n",
      "Epoch 29/500\n",
      "850/850 [==============================] - 0s 94us/step - loss: 0.3655 - acc: 0.8565 - val_loss: 0.6094 - val_acc: 0.6600\n",
      "Epoch 30/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.3476 - acc: 0.8612 - val_loss: 0.6188 - val_acc: 0.6533\n",
      "Epoch 31/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.3309 - acc: 0.8753 - val_loss: 0.6171 - val_acc: 0.6733\n",
      "Epoch 32/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.3145 - acc: 0.8753 - val_loss: 0.6137 - val_acc: 0.6867\n",
      "Epoch 33/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.3009 - acc: 0.8859 - val_loss: 0.6269 - val_acc: 0.6733\n",
      "Epoch 34/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.2861 - acc: 0.8953 - val_loss: 0.6243 - val_acc: 0.6800\n",
      "Epoch 35/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.2743 - acc: 0.8988 - val_loss: 0.6437 - val_acc: 0.6867\n",
      "Epoch 36/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.2619 - acc: 0.9000 - val_loss: 0.6529 - val_acc: 0.6933\n",
      "Epoch 37/500\n",
      "850/850 [==============================] - 0s 94us/step - loss: 0.2500 - acc: 0.9082 - val_loss: 0.6504 - val_acc: 0.6800\n",
      "Epoch 38/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.2393 - acc: 0.9153 - val_loss: 0.6665 - val_acc: 0.6933\n",
      "Epoch 39/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.2285 - acc: 0.9165 - val_loss: 0.6821 - val_acc: 0.6867\n",
      "Epoch 40/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.2186 - acc: 0.9235 - val_loss: 0.6740 - val_acc: 0.7133\n",
      "Epoch 41/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.2094 - acc: 0.9224 - val_loss: 0.6885 - val_acc: 0.7067\n",
      "Epoch 42/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.1994 - acc: 0.9247 - val_loss: 0.7027 - val_acc: 0.7133\n",
      "Epoch 43/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1913 - acc: 0.9306 - val_loss: 0.7021 - val_acc: 0.7200\n",
      "Epoch 44/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.1823 - acc: 0.9329 - val_loss: 0.7114 - val_acc: 0.7267\n",
      "Epoch 45/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.1743 - acc: 0.9353 - val_loss: 0.7209 - val_acc: 0.7267\n",
      "Epoch 46/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1675 - acc: 0.9388 - val_loss: 0.7264 - val_acc: 0.7200\n",
      "Epoch 47/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.1598 - acc: 0.9400 - val_loss: 0.7502 - val_acc: 0.7200\n",
      "Epoch 48/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1539 - acc: 0.9424 - val_loss: 0.7555 - val_acc: 0.7267\n",
      "Epoch 49/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1463 - acc: 0.9494 - val_loss: 0.7570 - val_acc: 0.7267\n",
      "Epoch 50/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1398 - acc: 0.9506 - val_loss: 0.7873 - val_acc: 0.7200\n",
      "Epoch 51/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.1338 - acc: 0.9541 - val_loss: 0.8187 - val_acc: 0.7067\n",
      "Epoch 52/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1290 - acc: 0.9565 - val_loss: 0.7970 - val_acc: 0.7267\n",
      "Epoch 53/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1228 - acc: 0.9612 - val_loss: 0.8053 - val_acc: 0.7333\n",
      "Epoch 54/500\n",
      "850/850 [==============================] - 0s 94us/step - loss: 0.1178 - acc: 0.9659 - val_loss: 0.8258 - val_acc: 0.7267\n",
      "Epoch 55/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.1127 - acc: 0.9635 - val_loss: 0.8394 - val_acc: 0.7267\n",
      "Epoch 56/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.1079 - acc: 0.9671 - val_loss: 0.8665 - val_acc: 0.7133\n",
      "Epoch 57/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.1029 - acc: 0.9671 - val_loss: 0.8510 - val_acc: 0.7333\n",
      "Epoch 58/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0991 - acc: 0.9718 - val_loss: 0.8784 - val_acc: 0.7200\n",
      "Epoch 59/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0943 - acc: 0.9706 - val_loss: 0.8822 - val_acc: 0.7267\n",
      "Epoch 60/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0904 - acc: 0.9729 - val_loss: 0.9015 - val_acc: 0.7267\n",
      "Epoch 61/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 80us/step - loss: 0.0865 - acc: 0.9729 - val_loss: 0.9114 - val_acc: 0.7267\n",
      "Epoch 62/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0834 - acc: 0.9741 - val_loss: 0.9415 - val_acc: 0.7133\n",
      "Epoch 63/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0796 - acc: 0.9753 - val_loss: 0.9488 - val_acc: 0.7267\n",
      "Epoch 64/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0765 - acc: 0.9776 - val_loss: 0.9707 - val_acc: 0.7133\n",
      "Epoch 65/500\n",
      "850/850 [==============================] - 0s 72us/step - loss: 0.0735 - acc: 0.9765 - val_loss: 0.9879 - val_acc: 0.7133\n",
      "Epoch 66/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0704 - acc: 0.9776 - val_loss: 1.0252 - val_acc: 0.7133\n",
      "Epoch 67/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0675 - acc: 0.9788 - val_loss: 1.0164 - val_acc: 0.7133\n",
      "Epoch 68/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0648 - acc: 0.9800 - val_loss: 1.0534 - val_acc: 0.7067\n",
      "Epoch 69/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0624 - acc: 0.9800 - val_loss: 1.0463 - val_acc: 0.7200\n",
      "Epoch 70/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0603 - acc: 0.9800 - val_loss: 1.0607 - val_acc: 0.7200\n",
      "Epoch 71/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0579 - acc: 0.9824 - val_loss: 1.0815 - val_acc: 0.7067\n",
      "Epoch 72/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0557 - acc: 0.9835 - val_loss: 1.1096 - val_acc: 0.7067\n",
      "Epoch 73/500\n",
      "850/850 [==============================] - 0s 79us/step - loss: 0.0530 - acc: 0.9835 - val_loss: 1.1198 - val_acc: 0.7067\n",
      "Epoch 74/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0514 - acc: 0.9824 - val_loss: 1.1371 - val_acc: 0.7067\n",
      "Epoch 75/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0492 - acc: 0.9835 - val_loss: 1.1501 - val_acc: 0.7133\n",
      "Epoch 76/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0474 - acc: 0.9835 - val_loss: 1.1930 - val_acc: 0.7067\n",
      "Epoch 77/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0465 - acc: 0.9835 - val_loss: 1.1979 - val_acc: 0.7133\n",
      "Epoch 78/500\n",
      "850/850 [==============================] - 0s 69us/step - loss: 0.0448 - acc: 0.9835 - val_loss: 1.2073 - val_acc: 0.7067\n",
      "Epoch 79/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0431 - acc: 0.9847 - val_loss: 1.2145 - val_acc: 0.7067\n",
      "Epoch 80/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0413 - acc: 0.9847 - val_loss: 1.2417 - val_acc: 0.7000\n",
      "Epoch 81/500\n",
      "850/850 [==============================] - 0s 73us/step - loss: 0.0397 - acc: 0.9871 - val_loss: 1.2377 - val_acc: 0.7133\n",
      "Epoch 82/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0382 - acc: 0.9871 - val_loss: 1.2624 - val_acc: 0.7133\n",
      "Epoch 83/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0376 - acc: 0.9859 - val_loss: 1.2874 - val_acc: 0.7067\n",
      "Epoch 84/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0356 - acc: 0.9882 - val_loss: 1.3032 - val_acc: 0.7067\n",
      "Epoch 85/500\n",
      "850/850 [==============================] - 0s 73us/step - loss: 0.0347 - acc: 0.9882 - val_loss: 1.3126 - val_acc: 0.7133\n",
      "Epoch 86/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0337 - acc: 0.9894 - val_loss: 1.3606 - val_acc: 0.7000\n",
      "Epoch 87/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0327 - acc: 0.9894 - val_loss: 1.3791 - val_acc: 0.7000\n",
      "Epoch 88/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0314 - acc: 0.9894 - val_loss: 1.4047 - val_acc: 0.7067\n",
      "Epoch 89/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0309 - acc: 0.9871 - val_loss: 1.3890 - val_acc: 0.7000\n",
      "Epoch 90/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0299 - acc: 0.9894 - val_loss: 1.4167 - val_acc: 0.7000\n",
      "Epoch 91/500\n",
      "850/850 [==============================] - 0s 74us/step - loss: 0.0294 - acc: 0.9894 - val_loss: 1.4481 - val_acc: 0.7000\n",
      "Epoch 92/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0284 - acc: 0.9882 - val_loss: 1.4442 - val_acc: 0.7067\n",
      "Epoch 93/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0273 - acc: 0.9894 - val_loss: 1.4510 - val_acc: 0.7067\n",
      "Epoch 94/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0265 - acc: 0.9906 - val_loss: 1.4941 - val_acc: 0.7000\n",
      "Epoch 95/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0259 - acc: 0.9894 - val_loss: 1.4869 - val_acc: 0.7067\n",
      "Epoch 96/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0257 - acc: 0.9918 - val_loss: 1.5212 - val_acc: 0.7000\n",
      "Epoch 97/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0249 - acc: 0.9918 - val_loss: 1.5276 - val_acc: 0.7067\n",
      "Epoch 98/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0243 - acc: 0.9918 - val_loss: 1.5408 - val_acc: 0.7067\n",
      "Epoch 99/500\n",
      "850/850 [==============================] - 0s 76us/step - loss: 0.0239 - acc: 0.9918 - val_loss: 1.5639 - val_acc: 0.7067\n",
      "Epoch 100/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0228 - acc: 0.9929 - val_loss: 1.5614 - val_acc: 0.7067\n",
      "Epoch 101/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0231 - acc: 0.9918 - val_loss: 1.6119 - val_acc: 0.7067\n",
      "Epoch 102/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0224 - acc: 0.9918 - val_loss: 1.6160 - val_acc: 0.7067\n",
      "Epoch 103/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0219 - acc: 0.9918 - val_loss: 1.6306 - val_acc: 0.7067\n",
      "Epoch 104/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0217 - acc: 0.9918 - val_loss: 1.6605 - val_acc: 0.7000\n",
      "Epoch 105/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0208 - acc: 0.9929 - val_loss: 1.6582 - val_acc: 0.7067\n",
      "Epoch 106/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0203 - acc: 0.9929 - val_loss: 1.6971 - val_acc: 0.6933\n",
      "Epoch 107/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0203 - acc: 0.9918 - val_loss: 1.7160 - val_acc: 0.6933\n",
      "Epoch 108/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0191 - acc: 0.9929 - val_loss: 1.7708 - val_acc: 0.6867\n",
      "Epoch 109/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0200 - acc: 0.9929 - val_loss: 1.7586 - val_acc: 0.6800\n",
      "Epoch 110/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0190 - acc: 0.9929 - val_loss: 1.7574 - val_acc: 0.6933\n",
      "Epoch 111/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0183 - acc: 0.9929 - val_loss: 1.7511 - val_acc: 0.7000\n",
      "Epoch 112/500\n",
      "850/850 [==============================] - 0s 68us/step - loss: 0.0182 - acc: 0.9929 - val_loss: 1.7600 - val_acc: 0.7067\n",
      "Epoch 113/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0179 - acc: 0.9918 - val_loss: 1.8168 - val_acc: 0.6933\n",
      "Epoch 114/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0181 - acc: 0.9918 - val_loss: 1.8338 - val_acc: 0.6933\n",
      "Epoch 115/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0174 - acc: 0.9929 - val_loss: 1.8145 - val_acc: 0.6933\n",
      "Epoch 116/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0173 - acc: 0.9906 - val_loss: 1.8329 - val_acc: 0.6933\n",
      "Epoch 117/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0172 - acc: 0.9929 - val_loss: 1.8588 - val_acc: 0.6933\n",
      "Epoch 118/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0167 - acc: 0.9929 - val_loss: 1.8912 - val_acc: 0.7000\n",
      "Epoch 119/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0164 - acc: 0.9941 - val_loss: 1.9027 - val_acc: 0.7067\n",
      "Epoch 120/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0164 - acc: 0.9929 - val_loss: 1.9155 - val_acc: 0.7067\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 75us/step - loss: 0.0163 - acc: 0.9929 - val_loss: 1.9292 - val_acc: 0.6933\n",
      "Epoch 122/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0159 - acc: 0.9941 - val_loss: 1.9450 - val_acc: 0.6933\n",
      "Epoch 123/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0158 - acc: 0.9929 - val_loss: 1.9532 - val_acc: 0.6933\n",
      "Epoch 124/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0156 - acc: 0.9929 - val_loss: 1.9650 - val_acc: 0.6933\n",
      "Epoch 125/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0156 - acc: 0.9941 - val_loss: 1.9973 - val_acc: 0.7067\n",
      "Epoch 126/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0151 - acc: 0.9929 - val_loss: 2.0112 - val_acc: 0.7067\n",
      "Epoch 127/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0149 - acc: 0.9929 - val_loss: 2.0441 - val_acc: 0.7067\n",
      "Epoch 128/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0157 - acc: 0.9941 - val_loss: 2.0338 - val_acc: 0.6933\n",
      "Epoch 129/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0149 - acc: 0.9941 - val_loss: 2.0435 - val_acc: 0.6867\n",
      "Epoch 130/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0146 - acc: 0.9929 - val_loss: 2.0614 - val_acc: 0.6867\n",
      "Epoch 131/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0146 - acc: 0.9929 - val_loss: 2.0804 - val_acc: 0.6867\n",
      "Epoch 132/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0148 - acc: 0.9941 - val_loss: 2.0848 - val_acc: 0.6867\n",
      "Epoch 133/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0143 - acc: 0.9929 - val_loss: 2.0779 - val_acc: 0.6867\n",
      "Epoch 134/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0144 - acc: 0.9929 - val_loss: 2.0979 - val_acc: 0.6867\n",
      "Epoch 135/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0144 - acc: 0.9941 - val_loss: 2.1276 - val_acc: 0.6867\n",
      "Epoch 136/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0144 - acc: 0.9941 - val_loss: 2.1454 - val_acc: 0.6867\n",
      "Epoch 137/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0140 - acc: 0.9929 - val_loss: 2.1546 - val_acc: 0.6867\n",
      "Epoch 138/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0140 - acc: 0.9941 - val_loss: 2.1519 - val_acc: 0.6867\n",
      "Epoch 139/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0140 - acc: 0.9929 - val_loss: 2.1531 - val_acc: 0.6867\n",
      "Epoch 140/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0138 - acc: 0.9941 - val_loss: 2.1756 - val_acc: 0.6867\n",
      "Epoch 141/500\n",
      "850/850 [==============================] - 0s 65us/step - loss: 0.0139 - acc: 0.9929 - val_loss: 2.2129 - val_acc: 0.6933\n",
      "Epoch 142/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0139 - acc: 0.9929 - val_loss: 2.2134 - val_acc: 0.6867\n",
      "Epoch 143/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0136 - acc: 0.9941 - val_loss: 2.2273 - val_acc: 0.6933\n",
      "Epoch 144/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0139 - acc: 0.9929 - val_loss: 2.2389 - val_acc: 0.6933\n",
      "Epoch 145/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0133 - acc: 0.9941 - val_loss: 2.2398 - val_acc: 0.6867\n",
      "Epoch 146/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0134 - acc: 0.9929 - val_loss: 2.2593 - val_acc: 0.6933\n",
      "Epoch 147/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0135 - acc: 0.9953 - val_loss: 2.2792 - val_acc: 0.6933\n",
      "Epoch 148/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0135 - acc: 0.9929 - val_loss: 2.2735 - val_acc: 0.6867\n",
      "Epoch 149/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0133 - acc: 0.9941 - val_loss: 2.2835 - val_acc: 0.6867\n",
      "Epoch 150/500\n",
      "850/850 [==============================] - 0s 69us/step - loss: 0.0134 - acc: 0.9941 - val_loss: 2.3144 - val_acc: 0.6933\n",
      "Epoch 151/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0136 - acc: 0.9929 - val_loss: 2.3128 - val_acc: 0.6933\n",
      "Epoch 152/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0133 - acc: 0.9941 - val_loss: 2.3173 - val_acc: 0.6933\n",
      "Epoch 153/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.3571 - val_acc: 0.7000\n",
      "Epoch 154/500\n",
      "850/850 [==============================] - 0s 76us/step - loss: 0.0136 - acc: 0.9941 - val_loss: 2.3526 - val_acc: 0.6867\n",
      "Epoch 155/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.3324 - val_acc: 0.6933\n",
      "Epoch 156/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0130 - acc: 0.9941 - val_loss: 2.3799 - val_acc: 0.7000\n",
      "Epoch 157/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0128 - acc: 0.9941 - val_loss: 2.3563 - val_acc: 0.6933\n",
      "Epoch 158/500\n",
      "850/850 [==============================] - 0s 69us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.3363 - val_acc: 0.6867\n",
      "Epoch 159/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.4026 - val_acc: 0.7000\n",
      "Epoch 160/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0132 - acc: 0.9941 - val_loss: 2.3825 - val_acc: 0.6933\n",
      "Epoch 161/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0131 - acc: 0.9941 - val_loss: 2.4097 - val_acc: 0.6867\n",
      "Epoch 162/500\n",
      "850/850 [==============================] - 0s 74us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.4185 - val_acc: 0.6867\n",
      "Epoch 163/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0130 - acc: 0.9929 - val_loss: 2.4375 - val_acc: 0.7000\n",
      "Epoch 164/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0128 - acc: 0.9929 - val_loss: 2.4217 - val_acc: 0.6867\n",
      "Epoch 165/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0127 - acc: 0.9929 - val_loss: 2.4353 - val_acc: 0.6867\n",
      "Epoch 166/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.5023 - val_acc: 0.7000\n",
      "Epoch 167/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0130 - acc: 0.9929 - val_loss: 2.4591 - val_acc: 0.7000\n",
      "Epoch 168/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.4631 - val_acc: 0.7000\n",
      "Epoch 169/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0128 - acc: 0.9918 - val_loss: 2.4701 - val_acc: 0.7000\n",
      "Epoch 170/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.5053 - val_acc: 0.7000\n",
      "Epoch 171/500\n",
      "850/850 [==============================] - 0s 78us/step - loss: 0.0125 - acc: 0.9953 - val_loss: 2.4697 - val_acc: 0.6867\n",
      "Epoch 172/500\n",
      "850/850 [==============================] - 0s 74us/step - loss: 0.0117 - acc: 0.9953 - val_loss: 2.5615 - val_acc: 0.7000\n",
      "Epoch 173/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0134 - acc: 0.9918 - val_loss: 2.5069 - val_acc: 0.7000\n",
      "Epoch 174/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.5051 - val_acc: 0.7000\n",
      "Epoch 175/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.5036 - val_acc: 0.6867\n",
      "Epoch 176/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.5123 - val_acc: 0.6867\n",
      "Epoch 177/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0130 - acc: 0.9941 - val_loss: 2.5117 - val_acc: 0.7000\n",
      "Epoch 178/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.5697 - val_acc: 0.7000\n",
      "Epoch 179/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0132 - acc: 0.9929 - val_loss: 2.5363 - val_acc: 0.6867\n",
      "Epoch 180/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0121 - acc: 0.9941 - val_loss: 2.5146 - val_acc: 0.7000\n",
      "Epoch 181/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 71us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.5428 - val_acc: 0.7000\n",
      "Epoch 182/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.5185 - val_acc: 0.7000\n",
      "Epoch 183/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.5843 - val_acc: 0.7000\n",
      "Epoch 184/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.6082 - val_acc: 0.7000\n",
      "Epoch 185/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0126 - acc: 0.9929 - val_loss: 2.5506 - val_acc: 0.7000\n",
      "Epoch 186/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.5429 - val_acc: 0.7000\n",
      "Epoch 187/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.5744 - val_acc: 0.7000\n",
      "Epoch 188/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0128 - acc: 0.9929 - val_loss: 2.5799 - val_acc: 0.7000\n",
      "Epoch 189/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0118 - acc: 0.9941 - val_loss: 2.5542 - val_acc: 0.7000\n",
      "Epoch 190/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0131 - acc: 0.9941 - val_loss: 2.6009 - val_acc: 0.7000\n",
      "Epoch 191/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.6557 - val_acc: 0.7000\n",
      "Epoch 192/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0132 - acc: 0.9929 - val_loss: 2.6400 - val_acc: 0.7067\n",
      "Epoch 193/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.6844 - val_acc: 0.7067\n",
      "Epoch 194/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0129 - acc: 0.9918 - val_loss: 2.6606 - val_acc: 0.7067\n",
      "Epoch 195/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0126 - acc: 0.9918 - val_loss: 2.6315 - val_acc: 0.7000\n",
      "Epoch 196/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0129 - acc: 0.9906 - val_loss: 2.6393 - val_acc: 0.7000\n",
      "Epoch 197/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0123 - acc: 0.9918 - val_loss: 2.6192 - val_acc: 0.7000\n",
      "Epoch 198/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.6750 - val_acc: 0.7133\n",
      "Epoch 199/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.6961 - val_acc: 0.7067\n",
      "Epoch 200/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.6795 - val_acc: 0.7067\n",
      "Epoch 201/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9941 - val_loss: 2.6585 - val_acc: 0.7067\n",
      "Epoch 202/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.6697 - val_acc: 0.7067\n",
      "Epoch 203/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.6638 - val_acc: 0.7067\n",
      "Epoch 204/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.9929 - val_loss: 2.6668 - val_acc: 0.7067\n",
      "Epoch 205/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.6879 - val_acc: 0.7067\n",
      "Epoch 206/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.7116 - val_acc: 0.7200\n",
      "Epoch 207/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.7119 - val_acc: 0.7200\n",
      "Epoch 208/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0129 - acc: 0.9929 - val_loss: 2.6999 - val_acc: 0.7067\n",
      "Epoch 209/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.6777 - val_acc: 0.7200\n",
      "Epoch 210/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.9929 - val_loss: 2.7216 - val_acc: 0.7067\n",
      "Epoch 211/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9918 - val_loss: 2.6937 - val_acc: 0.7133\n",
      "Epoch 212/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.7186 - val_acc: 0.7067\n",
      "Epoch 213/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.7350 - val_acc: 0.7067\n",
      "Epoch 214/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9929 - val_loss: 2.7349 - val_acc: 0.7133\n",
      "Epoch 215/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.7501 - val_acc: 0.7200\n",
      "Epoch 216/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0121 - acc: 0.9953 - val_loss: 2.7850 - val_acc: 0.7200\n",
      "Epoch 217/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9941 - val_loss: 2.7794 - val_acc: 0.7200\n",
      "Epoch 218/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.7399 - val_acc: 0.7133\n",
      "Epoch 219/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.7700 - val_acc: 0.7267\n",
      "Epoch 220/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.7892 - val_acc: 0.7200\n",
      "Epoch 221/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.7517 - val_acc: 0.7200\n",
      "Epoch 222/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9929 - val_loss: 2.7651 - val_acc: 0.7133\n",
      "Epoch 223/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.7431 - val_acc: 0.7200\n",
      "Epoch 224/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.7544 - val_acc: 0.7200\n",
      "Epoch 225/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9929 - val_loss: 2.7576 - val_acc: 0.7200\n",
      "Epoch 226/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.7850 - val_acc: 0.7133\n",
      "Epoch 227/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.7926 - val_acc: 0.7267\n",
      "Epoch 228/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.7817 - val_acc: 0.7200\n",
      "Epoch 229/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.7845 - val_acc: 0.7200\n",
      "Epoch 230/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.7928 - val_acc: 0.7200\n",
      "Epoch 231/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.7992 - val_acc: 0.7200\n",
      "Epoch 232/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.9941 - val_loss: 2.8166 - val_acc: 0.7267\n",
      "Epoch 233/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8122 - val_acc: 0.7133\n",
      "Epoch 234/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.7958 - val_acc: 0.7133\n",
      "Epoch 235/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8220 - val_acc: 0.7267\n",
      "Epoch 236/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.9941 - val_loss: 2.8112 - val_acc: 0.7200\n",
      "Epoch 237/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9918 - val_loss: 2.8094 - val_acc: 0.7200\n",
      "Epoch 238/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.8184 - val_acc: 0.7200\n",
      "Epoch 239/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8164 - val_acc: 0.7200\n",
      "Epoch 240/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.8048 - val_acc: 0.7133\n",
      "Epoch 241/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9941 - val_loss: 2.8231 - val_acc: 0.7200\n",
      "Epoch 242/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0115 - acc: 0.9929 - val_loss: 2.8662 - val_acc: 0.7267\n",
      "Epoch 243/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8357 - val_acc: 0.7333\n",
      "Epoch 244/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8440 - val_acc: 0.7333\n",
      "Epoch 245/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8296 - val_acc: 0.7200\n",
      "Epoch 246/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.8417 - val_acc: 0.7333\n",
      "Epoch 247/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8440 - val_acc: 0.7333\n",
      "Epoch 248/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.8396 - val_acc: 0.7200\n",
      "Epoch 249/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9906 - val_loss: 2.8303 - val_acc: 0.7200\n",
      "Epoch 250/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.9918 - val_loss: 2.7986 - val_acc: 0.7067\n",
      "Epoch 251/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.8333 - val_acc: 0.7133\n",
      "Epoch 252/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0130 - acc: 0.9941 - val_loss: 2.8612 - val_acc: 0.7200\n",
      "Epoch 253/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8882 - val_acc: 0.7267\n",
      "Epoch 254/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.9929 - val_loss: 2.8508 - val_acc: 0.7200\n",
      "Epoch 255/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.8820 - val_acc: 0.7333\n",
      "Epoch 256/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0130 - acc: 0.9929 - val_loss: 2.8660 - val_acc: 0.7333\n",
      "Epoch 257/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.9918 - val_loss: 2.8228 - val_acc: 0.7133\n",
      "Epoch 258/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9906 - val_loss: 2.8183 - val_acc: 0.7133\n",
      "Epoch 259/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.8725 - val_acc: 0.7200\n",
      "Epoch 260/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.8773 - val_acc: 0.7200\n",
      "Epoch 261/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8624 - val_acc: 0.7200\n",
      "Epoch 262/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8325 - val_acc: 0.7133\n",
      "Epoch 263/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8318 - val_acc: 0.7133\n",
      "Epoch 264/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.8765 - val_acc: 0.7200\n",
      "Epoch 265/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8747 - val_acc: 0.7200\n",
      "Epoch 266/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8714 - val_acc: 0.7200\n",
      "Epoch 267/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.8740 - val_acc: 0.7200\n",
      "Epoch 268/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.9941 - val_loss: 2.8559 - val_acc: 0.7133\n",
      "Epoch 269/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9918 - val_loss: 2.8677 - val_acc: 0.7200\n",
      "Epoch 270/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8829 - val_acc: 0.7200\n",
      "Epoch 271/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.8702 - val_acc: 0.7200\n",
      "Epoch 272/500\n",
      "850/850 [==============================] - 0s 77us/step - loss: 0.0122 - acc: 0.9918 - val_loss: 2.8540 - val_acc: 0.7133\n",
      "Epoch 273/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.8693 - val_acc: 0.7200\n",
      "Epoch 274/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8823 - val_acc: 0.7200\n",
      "Epoch 275/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8784 - val_acc: 0.7200\n",
      "Epoch 276/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.9182 - val_acc: 0.7267\n",
      "Epoch 277/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.9342 - val_acc: 0.7333\n",
      "Epoch 278/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8864 - val_acc: 0.7200\n",
      "Epoch 279/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.8570 - val_acc: 0.7133\n",
      "Epoch 280/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.9093 - val_acc: 0.7267\n",
      "Epoch 281/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8998 - val_acc: 0.7200\n",
      "Epoch 282/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.8945 - val_acc: 0.7200\n",
      "Epoch 283/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.9076 - val_acc: 0.7133\n",
      "Epoch 284/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0131 - acc: 0.9941 - val_loss: 2.9054 - val_acc: 0.7133\n",
      "Epoch 285/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.8961 - val_acc: 0.7200\n",
      "Epoch 286/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.9037 - val_acc: 0.7133\n",
      "Epoch 287/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.9034 - val_acc: 0.7133\n",
      "Epoch 288/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0127 - acc: 0.9929 - val_loss: 2.8942 - val_acc: 0.7200\n",
      "Epoch 289/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9953 - val_loss: 2.8957 - val_acc: 0.7200\n",
      "Epoch 290/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.8868 - val_acc: 0.7200\n",
      "Epoch 291/500\n",
      "850/850 [==============================] - 0s 89us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.8988 - val_acc: 0.7200\n",
      "Epoch 292/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.9087 - val_acc: 0.7133\n",
      "Epoch 293/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.8537 - val_acc: 0.7067\n",
      "Epoch 294/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8852 - val_acc: 0.7200\n",
      "Epoch 295/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.9223 - val_acc: 0.7267\n",
      "Epoch 296/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.9311 - val_acc: 0.7267\n",
      "Epoch 297/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.9929 - val_loss: 2.8608 - val_acc: 0.7067\n",
      "Epoch 298/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.8952 - val_acc: 0.7133\n",
      "Epoch 299/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.8989 - val_acc: 0.7133\n",
      "Epoch 300/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.9157 - val_acc: 0.7267\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 71us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.9038 - val_acc: 0.7133\n",
      "Epoch 302/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.9051 - val_acc: 0.7267\n",
      "Epoch 303/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.9009 - val_acc: 0.7267\n",
      "Epoch 304/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9331 - val_acc: 0.7267\n",
      "Epoch 305/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.9119 - val_acc: 0.7267\n",
      "Epoch 306/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0129 - acc: 0.9941 - val_loss: 2.9343 - val_acc: 0.7267\n",
      "Epoch 307/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.8852 - val_acc: 0.7133\n",
      "Epoch 308/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.8687 - val_acc: 0.7133\n",
      "Epoch 309/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.8885 - val_acc: 0.7133\n",
      "Epoch 310/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0120 - acc: 0.9918 - val_loss: 2.8807 - val_acc: 0.7133\n",
      "Epoch 311/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.9001 - val_acc: 0.7133\n",
      "Epoch 312/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0123 - acc: 0.9918 - val_loss: 2.8841 - val_acc: 0.7133\n",
      "Epoch 313/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.8918 - val_acc: 0.7133\n",
      "Epoch 314/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.9929 - val_loss: 2.8968 - val_acc: 0.7133\n",
      "Epoch 315/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8793 - val_acc: 0.7133\n",
      "Epoch 316/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.9032 - val_acc: 0.7133\n",
      "Epoch 317/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9444 - val_acc: 0.7333\n",
      "Epoch 318/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.9114 - val_acc: 0.7267\n",
      "Epoch 319/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0119 - acc: 0.9941 - val_loss: 2.8908 - val_acc: 0.7133\n",
      "Epoch 320/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.9006 - val_acc: 0.7133\n",
      "Epoch 321/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0118 - acc: 0.9941 - val_loss: 2.9426 - val_acc: 0.7267\n",
      "Epoch 322/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.9918 - val_loss: 2.9105 - val_acc: 0.7133\n",
      "Epoch 323/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8996 - val_acc: 0.7133\n",
      "Epoch 324/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9929 - val_loss: 2.8892 - val_acc: 0.7133\n",
      "Epoch 325/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.9941 - val_loss: 2.9363 - val_acc: 0.7333\n",
      "Epoch 326/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8687 - val_acc: 0.7133\n",
      "Epoch 327/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9929 - val_loss: 2.8640 - val_acc: 0.7133\n",
      "Epoch 328/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8910 - val_acc: 0.7200\n",
      "Epoch 329/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0120 - acc: 0.9941 - val_loss: 2.9455 - val_acc: 0.7333\n",
      "Epoch 330/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9918 - val_loss: 2.9128 - val_acc: 0.7133\n",
      "Epoch 331/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9124 - val_acc: 0.7267\n",
      "Epoch 332/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.9147 - val_acc: 0.7267\n",
      "Epoch 333/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.9110 - val_acc: 0.7267\n",
      "Epoch 334/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.9047 - val_acc: 0.7133\n",
      "Epoch 335/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.9017 - val_acc: 0.7133\n",
      "Epoch 336/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0126 - acc: 0.9941 - val_loss: 2.8910 - val_acc: 0.7200\n",
      "Epoch 337/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9134 - val_acc: 0.7267\n",
      "Epoch 338/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0117 - acc: 0.9941 - val_loss: 2.9437 - val_acc: 0.7333\n",
      "Epoch 339/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0125 - acc: 0.9941 - val_loss: 2.9031 - val_acc: 0.7133\n",
      "Epoch 340/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.8593 - val_acc: 0.7200\n",
      "Epoch 341/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.9009 - val_acc: 0.7133\n",
      "Epoch 342/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.8807 - val_acc: 0.7267\n",
      "Epoch 343/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9282 - val_acc: 0.7267\n",
      "Epoch 344/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0126 - acc: 0.9929 - val_loss: 2.9141 - val_acc: 0.7133\n",
      "Epoch 345/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.9092 - val_acc: 0.7133\n",
      "Epoch 346/500\n",
      "850/850 [==============================] - 0s 85us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8866 - val_acc: 0.7267\n",
      "Epoch 347/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0124 - acc: 0.9941 - val_loss: 2.8872 - val_acc: 0.7267\n",
      "Epoch 348/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0116 - acc: 0.9941 - val_loss: 2.9159 - val_acc: 0.7133\n",
      "Epoch 349/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.9205 - val_acc: 0.7200\n",
      "Epoch 350/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0113 - acc: 0.9929 - val_loss: 2.8564 - val_acc: 0.7067\n",
      "Epoch 351/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.8863 - val_acc: 0.7267\n",
      "Epoch 352/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9167 - val_acc: 0.7200\n",
      "Epoch 353/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0116 - acc: 0.9941 - val_loss: 2.9534 - val_acc: 0.7333\n",
      "Epoch 354/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0120 - acc: 0.9929 - val_loss: 2.9124 - val_acc: 0.7200\n",
      "Epoch 355/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.8888 - val_acc: 0.7267\n",
      "Epoch 356/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9941 - val_loss: 2.9229 - val_acc: 0.7333\n",
      "Epoch 357/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0121 - acc: 0.9929 - val_loss: 2.9343 - val_acc: 0.7400\n",
      "Epoch 358/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0117 - acc: 0.9929 - val_loss: 2.8729 - val_acc: 0.7200\n",
      "Epoch 359/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0128 - acc: 0.9941 - val_loss: 2.9115 - val_acc: 0.7200\n",
      "Epoch 360/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0121 - acc: 0.9941 - val_loss: 2.9175 - val_acc: 0.7267\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/850 [==============================] - 0s 75us/step - loss: 0.0118 - acc: 0.9918 - val_loss: 2.8845 - val_acc: 0.7200\n",
      "Epoch 362/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0121 - acc: 0.9941 - val_loss: 2.8813 - val_acc: 0.7200\n",
      "Epoch 363/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0122 - acc: 0.9929 - val_loss: 2.8758 - val_acc: 0.7200\n",
      "Epoch 364/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0123 - acc: 0.9941 - val_loss: 2.9172 - val_acc: 0.7267\n",
      "Epoch 365/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0123 - acc: 0.9929 - val_loss: 2.8973 - val_acc: 0.7267\n",
      "Epoch 366/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.8852 - val_acc: 0.7200\n",
      "Epoch 367/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.9062 - val_acc: 0.7267\n",
      "Epoch 368/500\n",
      "850/850 [==============================] - 0s 80us/step - loss: 0.0118 - acc: 0.9941 - val_loss: 2.9639 - val_acc: 0.7333\n",
      "Epoch 369/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0124 - acc: 0.9906 - val_loss: 2.9123 - val_acc: 0.7333\n",
      "Epoch 370/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0114 - acc: 0.9929 - val_loss: 2.8807 - val_acc: 0.7133\n",
      "Epoch 371/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0119 - acc: 0.9929 - val_loss: 2.9250 - val_acc: 0.7267\n",
      "Epoch 372/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0127 - acc: 0.9941 - val_loss: 2.9134 - val_acc: 0.7267\n",
      "Epoch 373/500\n",
      "850/850 [==============================] - 0s 75us/step - loss: 0.0124 - acc: 0.9929 - val_loss: 2.9220 - val_acc: 0.7267\n",
      "Epoch 374/500\n",
      "850/850 [==============================] - 0s 66us/step - loss: 0.0119 - acc: 0.9941 - val_loss: 2.9387 - val_acc: 0.7400\n",
      "Epoch 375/500\n",
      "850/850 [==============================] - 0s 71us/step - loss: 0.0125 - acc: 0.9918 - val_loss: 2.9304 - val_acc: 0.7267\n",
      "Epoch 376/500\n",
      " 32/850 [>.............................] - ETA: 0s - loss: 0.0282 - acc: 0.9688"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 500, validation_data = (X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 599)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
