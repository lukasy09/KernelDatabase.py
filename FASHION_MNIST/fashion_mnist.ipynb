{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is coming again. This time, the data contains information what `fashion` looks like. We are going to classify things like: T-Shirts, boots etc (The full list is below and inside the code...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 What does that data looks for humans..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul style = \"list-style-type: none;\">\n",
       "    <li style = \"float:left;\"><img src =\"./assets/1.png\" width = 220px /></li>\n",
       "    <li style = \"float:left\"><img src =\"./assets/2.png\" width = 220px /></li>\n",
       "    <li style = \"float:left\"><img src =\"./assets/3.png\" width = 220px /></li>\n",
       "    <li style = \"float:left\"><img src =\"./assets/4.png\" width = 220px /></li>\n",
       "\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<ul style = \"list-style-type: none;\">\n",
    "    <li style = \"float:left;\"><img src =\"./assets/1.png\" width = 220px /></li>\n",
    "    <li style = \"float:left\"><img src =\"./assets/2.png\" width = 220px /></li>\n",
    "    <li style = \"float:left\"><img src =\"./assets/3.png\" width = 220px /></li>\n",
    "    <li style = \"float:left\"><img src =\"./assets/4.png\" width = 220px /></li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Possible object labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 T-shirt/top\n",
    "1 Trouser\n",
    "2 Pullover\n",
    "3 Dress\n",
    "4 Coat\n",
    "5 Sandal\n",
    "6 Shirt\n",
    "7 Sneaker\n",
    "8 Bag\n",
    "9 Ankle boot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Well-known library for uploading data & preprocessing\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"Visualising the data\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\"ML backend\"\"\"\n",
    "import tensorflow as tf\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"Keras dependencies for building model\"\"\"\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.utils.np_utils import to_categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Reading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"./data/fashion-mnist_train.csv\") # 28x28 images, 784 pixels\n",
    "dataframe_test = pd.read_csv(\"./data/fashion-mnist_test.csv\")  # Same like above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe.iloc[:, 1:].values # Data to train & validate during training\n",
    "Y = dataframe['label'].values #Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Scaling data/ Normalisation [0 - 1] range & Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255\n",
    "X = X.reshape(-1,28,28,1)\n",
    "Y = to_categorical(Y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip= False,\n",
    "    vertical_flip = False\n",
    ")\n",
    "\n",
    "data_generator.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Layers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters = 32, kernel_size = (5, 5),activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    Conv2D(filters = 32, kernel_size = (5, 5)),\n",
    "    MaxPool2D(pool_size = (2, 2)),\n",
    "    Dropout(0.2),\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3),activation = 'relu'),\n",
    "    Conv2D(filters = 64, kernel_size = (3, 3),activation = 'relu'),\n",
    "    MaxPool2D(pool_size = (2, 2), strides = (2, 2)),\n",
    "    Dropout(0.15),\n",
    "    Flatten(),\n",
    "    Dense(units = 256, activation = 'relu'),\n",
    "    Dense (units = 10, activation = 'softmax')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compilation, choosing loss function, optimizers and other parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "421/421 [==============================] - 180s 428ms/step - loss: 0.9330 - acc: 0.6483 - val_loss: 0.6023 - val_acc: 0.7613\n",
      "Epoch 2/10\n",
      "421/421 [==============================] - 178s 424ms/step - loss: 0.6548 - acc: 0.7494 - val_loss: 0.5653 - val_acc: 0.7733\n",
      "Epoch 3/10\n",
      "421/421 [==============================] - 193s 459ms/step - loss: 0.5820 - acc: 0.7787 - val_loss: 0.5229 - val_acc: 0.8005\n",
      "Epoch 4/10\n",
      "421/421 [==============================] - 185s 440ms/step - loss: 0.5386 - acc: 0.7955 - val_loss: 0.4512 - val_acc: 0.8270\n",
      "Epoch 5/10\n",
      "421/421 [==============================] - 173s 411ms/step - loss: 0.5095 - acc: 0.8055 - val_loss: 0.4591 - val_acc: 0.8288\n",
      "Epoch 6/10\n",
      "421/421 [==============================] - 171s 407ms/step - loss: 0.4834 - acc: 0.8182 - val_loss: 0.4176 - val_acc: 0.8418\n",
      "Epoch 7/10\n",
      "421/421 [==============================] - 170s 405ms/step - loss: 0.4546 - acc: 0.8310 - val_loss: 0.3983 - val_acc: 0.8495\n",
      "Epoch 8/10\n",
      "421/421 [==============================] - 175s 416ms/step - loss: 0.4363 - acc: 0.8379 - val_loss: 0.3866 - val_acc: 0.8590\n",
      "Epoch 9/10\n",
      "421/421 [==============================] - 179s 426ms/step - loss: 0.4196 - acc: 0.8426 - val_loss: 0.3625 - val_acc: 0.8617\n",
      "Epoch 10/10\n",
      "421/421 [==============================] - 171s 405ms/step - loss: 0.4173 - acc: 0.8449 - val_loss: 0.3810 - val_acc: 0.8598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xbb0507bda0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    data_generator.flow(X_train, Y_train, batch_size = 128),\n",
    "    epochs = 10,\n",
    "    steps_per_epoch = X_train.shape[0] // 128,\n",
    "    validation_data = (X_valid, Y_valid)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Saving to an external file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 .h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, './model_json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
